# -*- coding: utf-8 -*-
"""operators

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oeTDId4X_Z6HcUrAXu6HAG5xqL38Zr1Z
"""

# # /core/operators.py

# import pandas as pd
# import numpy as np

# # --------------------------------------------------------------------------- #
# # 이 파일의 함수들은 Zura Kakushadze의 "101 Formulaic Alphas" 논문 의
# # Appendix A.2. "Input Data"  섹션에 기술된 오퍼레이터들을 구현한 것입니다.
# # 모든 함수는 pandas DataFrame 또는 Series를 입력으로 받아 처리하도록 설계되었습니다.
# # --------------------------------------------------------------------------- #


# # --- Helper Functions ---

# def _get_rolling_group(df: pd.DataFrame, column: str, window: int) -> pd.core.window.rolling.RollingGroupby:
#     """Helper to get a rolling groupby object for time-series operations."""
#     return df.groupby('ticker')[column].rolling(window=window, min_periods=max(1, int(window * 0.8)))

# # --- Basic Math Operators ---

# def sign(series: pd.Series) -> pd.Series:
#     """ 데이터의 부호를 반환합니다 (양수: 1, 음수: -1, 0: 0). """
#     return np.sign(series)

# # --- Time-series Operators ---

# def delay(df: pd.DataFrame, column: str, d: int) -> pd.Series:
#     """
#     d일 전의 데이터 값을 가져옵니다. [cite: 970]
#     Args:
#         df (pd.DataFrame): 'ticker' 컬럼을 포함하는 전체 데이터프레임.
#         column (str): 대상 컬럼명.
#         d (int): 지연시킬 기간(일).
#     Returns:
#         pd.Series: 각 티커별로 d일만큼 지연된 데이터 시리즈.
#     """
#     return df.groupby('ticker')[column].shift(d)

# def delta(df: pd.DataFrame, column: str, d: int) -> pd.Series:
#     """
#     오늘의 데이터 값과 d일 전의 데이터 값 사이의 차이를 계산합니다. [cite: 974]
#     Args:
#         df, column, d: delay 함수와 동일.
#     Returns:
#         pd.Series: 현재 값과 지연된 값의 차이.
#     """
#     return df[column] - delay(df, column, d)

# def correlation(df: pd.DataFrame, col1: str, col2: str, d: int) -> pd.Series:
#     """
#     지난 d일 동안의 두 데이터 시리즈 간의 시계열 상관관계를 계산합니다. [cite: 971]
#     Args:
#         df (pd.DataFrame): 전체 데이터프레임.
#         col1 (str): 첫 번째 대상 컬럼.
#         col2 (str): 두 번째 대상 컬럼.
#         d (int): 상관관계를 계산할 기간(일).
#     Returns:
#         pd.Series: 계산된 상관관계 시리즈.
#     """
#     rolling_corr = _get_rolling_group(df, col1, d).corr(df[col2])
#     return rolling_corr.reset_index(level=0, drop=True)

# def covariance(df: pd.DataFrame, col1: str, col2: str, d: int) -> pd.Series:
#     """
#     지난 d일 동안의 두 데이터 시리즈 간의 시계열 공분산을 계산합니다. [cite: 972]
#     Args:
#         df, col1, col2, d: correlation 함수와 동일.
#     Returns:
#         pd.Series: 계산된 공분산 시리즈.
#     """
#     rolling_cov = _get_rolling_group(df, col1, d).cov(df[col2])
#     return rolling_cov.reset_index(level=0, drop=True)

# def ts_min(df: pd.DataFrame, column: str, d: int) -> pd.Series:
#     """ 지난 d일 동안의 시계열 최소값을 찾습니다. [cite: 980] """
#     rolling_min = _get_rolling_group(df, column, d).min()
#     return rolling_min.reset_index(level=0, drop=True)

# def ts_max(df: pd.DataFrame, column: str, d: int) -> pd.Series:
#     """ 지난 d일 동안의 시계열 최대값을 찾습니다. [cite: 982] """
#     rolling_max = _get_rolling_group(df, column, d).max()
#     return rolling_max.reset_index(level=0, drop=True)

# def ts_argmin(df: pd.DataFrame, column: str, d: int) -> pd.Series:
#     """ 지난 d일 동안 시계열 최소값이 발생한 날의 상대적 위치를 반환합니다. [cite: 984] """
#     rolling_argmin = _get_rolling_group(df, column, d).apply(np.argmin, raw=True)
#     return rolling_argmin.reset_index(level=0, drop=True)

# def ts_argmax(df: pd.DataFrame, column: str, d: int) -> pd.Series:
#     """ 지난 d일 동안 시계열 최대값이 발생한 날의 상대적 위치를 반환합니다. [cite: 983] """
#     rolling_argmax = _get_rolling_group(df, column, d).apply(np.argmax, raw=True)
#     return rolling_argmax.reset_index(level=0, drop=True)

# def ts_rank(df: pd.DataFrame, column: str, d: int) -> pd.Series:
#     """
#     지난 d일 동안의 시계열 순위를 계산합니다 (현재 값의 순위). [cite: 985]
#     결과는 0과 1 사이의 값으로 정규화됩니다.
#     """
#     rolling_rank = _get_rolling_group(df, column, d).apply(lambda w: w.rank(pct=True).iloc[-1], raw=False)
#     return rolling_rank.reset_index(level=0, drop=True)

# def stddev(df: pd.DataFrame, column: str, d: int) -> pd.Series:
#     """ 지난 d일 동안의 이동 시계열 표준편차를 계산합니다. [cite: 990] """
#     rolling_std = _get_rolling_group(df, column, d).std()
#     return rolling_std.reset_index(level=0, drop=True)

# def sum(df: pd.DataFrame, column: str, d: int) -> pd.Series:
#     """ 지난 d일 동안의 시계열 합계를 계산합니다. [cite: 988] """
#     rolling_sum = _get_rolling_group(df, column, d).sum()
#     return rolling_sum.reset_index(level=0, drop=True)

# def product(df: pd.DataFrame, column: str, d: int) -> pd.Series:
#     """ 지난 d일 동안의 시계열 곱을 계산합니다. [cite: 989] """
#     rolling_prod = _get_rolling_group(df, column, d).apply(np.prod, raw=True)
#     return rolling_prod.reset_index(level=0, drop=True)

# def decay_linear(df: pd.DataFrame, column: str, d: int) -> pd.Series:
#     """
#     지난 d일 동안 선형적으로 감소하는 가중치를 적용한 가중 이동 평균을 계산합니다. [cite: 976]
#     최신 데이터에 가장 높은 가중치(d)가 부여됩니다.
#     """
#     weights = np.arange(1, d + 1)

#     def weighted_average(series):
#         return np.convolve(series, weights, 'valid') / weights.sum()

#     rolling_decay = _get_rolling_group(df, column, d).apply(weighted_average, raw=True)
#     return rolling_decay.reset_index(level=0, drop=True)

# # --- Cross-sectional Operators ---

# def rank(df: pd.DataFrame, column: str) -> pd.Series:
#     """
#     횡단면 순위를 계산합니다. 즉, 각 날짜 내에서 모든 티커의 순위를 매깁니다. [cite: 969]
#     결과는 백분위 순위(0과 1 사이)로 반환됩니다.
#     """
#     return df.groupby('date')[column].rank(pct=True)

# def scale(df: pd.DataFrame, column: str, a: float = 1.0) -> pd.Series:
#     """
#     횡단면 데이터를 스케일링하여 절대값의 합이 'a'가 되도록 합니다. [cite: 973]
#     기본값 'a'는 1입니다.
#     """
#     scaler = df.groupby('date')[column].transform(lambda x: x.abs().sum())
#     return df[column] * a / scaler

# def indneutralize(df: pd.DataFrame, column: str, ind_col: str = 'industry') -> pd.Series:
#     """
#     산업(또는 다른 그룹)에 대해 데이터를 중립화합니다. [cite: 977]
#     각 날짜의 각 산업 그룹 내에서 데이터의 평균을 0으로 만듭니다.
#     Args:
#         df (pd.DataFrame): 'date', 'industry' 컬럼 포함.
#         column (str): 중립화할 대상 컬럼.
#         ind_col (str): 산업 그룹 컬럼명.
#     Returns:
#         pd.Series: 산업 중립화된 데이터 시리즈.
#     """
#     # 이 함수는 데이터프레임에 'industry'와 같은 산업 분류 컬럼이 존재한다고 가정합니다.
#     if ind_col not in df.columns:
#         # 산업 컬럼이 없으면 중립화를 수행하지 않고 원본 데이터를 반환
#         return df[column]

#     group_mean = df.groupby(['date', ind_col])[column].transform('mean')
#     return df[column] - group_mean


# # --- Aliases for convenience ---
# # 논문의 표현을 그대로 사용하기 위한 별칭 함수들

# min = ts_min
# max = ts_max
# signedpower = np.power

# /core/operators.py

import pandas as pd
import numpy as np

# 모든 함수는 멀티 인덱스(ticker, date)를 가진 Series를 입력으로 받습니다.

def _get_rolling_obj(series: pd.Series, window: int) -> pd.core.window.rolling.Rolling:
    """Helper to get a rolling object for time-series operations on a multi-index Series."""
    return series.groupby(level='ticker').rolling(window=window, min_periods=max(1, int(window * 0.8)))

# --- Basic Math Operators ---

def sign(series: pd.Series) -> pd.Series:
    """ 데이터의 부호를 반환합니다 (양수: 1, 음수: -1, 0: 0). """
    return np.sign(series)

# --- Time-series Operators ---

def delay(series: pd.Series, d: int) -> pd.Series:
    """ d일 전의 데이터 값을 가져옵니다. """
    return series.groupby(level='ticker').shift(d)

def delta(series: pd.Series, d: int) -> pd.Series:
    """ 오늘의 데이터 값과 d일 전의 데이터 값 사이의 차이를 계산합니다. """
    return series - series.groupby(level='ticker').shift(d)

def correlation(series1: pd.Series, series2: pd.Series, d: int) -> pd.Series:
    """ 지난 d일 동안의 두 데이터 시리즈 간의 시계열 상관관계를 계산합니다. """
    rolling_corr = _get_rolling_obj(series1, d).corr(series2)
    return rolling_corr.reset_index(level=0, drop=True)

def covariance(series1: pd.Series, series2: pd.Series, d: int) -> pd.Series:
    """ 지난 d일 동안의 두 데이터 시리즈 간의 시계열 공분산을 계산합니다. """
    rolling_cov = _get_rolling_obj(series1, d).cov(series2)
    return rolling_cov.reset_index(level=0, drop=True)

def ts_min(series: pd.Series, d: int) -> pd.Series:
    """ 지난 d일 동안의 시계열 최소값을 찾습니다. """
    rolling_min = _get_rolling_obj(series, d).min()
    return rolling_min.reset_index(level=0, drop=True)

def ts_max(series: pd.Series, d: int) -> pd.Series:
    """ 지난 d일 동안의 시계열 최대값을 찾습니다. """
    rolling_max = _get_rolling_obj(series, d).max()
    return rolling_max.reset_index(level=0, drop=True)

def ts_argmin(series: pd.Series, d: int) -> pd.Series:
    """ 지난 d일 동안 시계열 최소값이 발생한 날의 상대적 위치를 반환합니다. """
    rolling_argmin = _get_rolling_obj(series, d).apply(np.argmin, raw=True)
    return rolling_argmin.reset_index(level=0, drop=True)

def ts_argmax(series: pd.Series, d: int) -> pd.Series:
    """ 지난 d일 동안 시계열 최대값이 발생한 날의 상대적 위치를 반환합니다. """
    rolling_argmax = _get_rolling_obj(series, d).apply(np.argmax, raw=True)
    return rolling_argmax.reset_index(level=0, drop=True)

def ts_rank(series: pd.Series, d: int) -> pd.Series:
    """ 지난 d일 동안의 시계열 순위를 계산합니다 (현재 값의 순위). """
    rolling_rank = _get_rolling_obj(series, d).apply(lambda w: w.rank(pct=True).iloc[-1], raw=False)
    return rolling_rank.reset_index(level=0, drop=True)

def stddev(series: pd.Series, d: int) -> pd.Series:
    """ 지난 d일 동안의 이동 시계열 표준편차를 계산합니다. """
    rolling_std = _get_rolling_obj(series, d).std()
    return rolling_std.reset_index(level=0, drop=True)

def ts_sum(series: pd.Series, d: int) -> pd.Series:
    """ 지난 d일 동안의 시계열 합계를 계산합니다. """
    rolling_sum = _get_rolling_obj(series, d).sum()
    return rolling_sum.reset_index(level=0, drop=True)

def ts_product(series: pd.Series, d: int) -> pd.Series:
    """ 지난 d일 동안의 시계열 곱을 계산합니다. """
    rolling_prod = _get_rolling_obj(series, d).apply(np.prod, raw=True)
    return rolling_prod.reset_index(level=0, drop=True)

def decay_linear(series: pd.Series, d: int) -> pd.Series:
    """ 지난 d일 동안 선형적으로 감소하는 가중치를 적용한 가중 이동 평균을 계산합니다. """
    weights = np.arange(1, d + 1)
    rolling_decay = _get_rolling_obj(series, d).apply(lambda s: np.dot(s, weights) / weights.sum(), raw=True)
    return rolling_decay.reset_index(level=0, drop=True)

# --- Cross-sectional Operators ---

def rank(series: pd.Series) -> pd.Series:
    """ 횡단면 순위를 계산합니다. 즉, 각 날짜 내에서 모든 티커의 순위를 매깁니다. """
    return series.groupby(level='date').rank(pct=True)

def scale(series: pd.Series, a: float = 1.0) -> pd.Series:
    """ 횡단면 데이터를 스케일링하여 절대값의 합이 'a'가 되도록 합니다. """
    scaler = series.groupby(level='date').transform(lambda x: x.abs().sum())
    return series * a / scaler

def indneutralize(series: pd.Series, industry_series: pd.Series) -> pd.Series:
    """ 산업(또는 다른 그룹)에 대해 데이터를 중립화합니다. """
    group_mean = series.groupby([series.index.get_level_values('date'), industry_series]).transform('mean')
    return series - group_mean

# # --- Aliases for convenience ---
# min = ts_min
# max = ts_max
# signedpower = np.power
# sum = ts_sum      # sum이 내장 함수이므로 ts_sum으로 구현 후 별칭 사용
# product = ts_product # product도 마찬가지
